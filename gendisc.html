<!doctype html>
<html>
    <head>
        <title>Generative VS Discriminative ML models</title>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <link href="./css/impress-common.css" rel="stylesheet" />
        <link href="./css/presentation.css" rel="stylesheet" />
    </head>
    <body>
        <div id="impress" data-transition-duration="500">
            <div id="Deep-field" class="step skip background" data-x="15000" data-y="3000" data-z="-500" data-scale="30">
                <img src="images/background.jpeg" width="900"/>
            </div>

            <div id="Overview" class="step" data-x="15000" data-y="2000" data-scale="20">
                <h1>
                    Generative Deep Neural Models
                </h1>
            </div>

            <div id="Agenda" class="step" data-x="5000" data-y="-4200">
                <h1>Agenda</h1>
                <ul>
                    <li>Discriminative VS Generative models</li>
                    <li>Embedding-space / manifold hypothesis</li>
                    <li>Generative approaches</li>
                    <ul>
                        <li>Variational Autoencoders</li>
                        <li>Normalizing Flows</li>
                        <li>Denoising Diffusion Probabilistic Models</li>
                        <li>Generative Adversarial Networks</li>
                    </ul>
                    <li>Performances</li>
                    <li>New Generative opportunities</li>
                    <li>Conclusions</li>
                </ul>
            </div>

            <!-- Definition -->

            <div id="Discriminative" class="step" data-x="7000" data-y="000">
                <h1>Discriminative models</h1>
                <center>
                    Given some pairs $\mathcal{XY}=\{(x_i,y_i)\}$... what about learning:
                    $$f:\mathcal{X}\to\mathcal{Y} = f(x) = \arg\max_yp(y|x)$$
                </center>
                <img src="images/discriminative.png" width="500"/>
                <did>Maximum posterior approach.</did>
            </div>

            <div id="Generative" class="step" data-rel-x="1000" data-rel-y="0">
                <h1>Generative models</h1>
                <center>
                    What about learning the per-class conditional distributions?
                    $$f:\mathcal{X}\to\mathcal{Y} = f(x) = \arg\max_yp(x|y)$$
                </center>
                <img src="images/generative.png" width="500"/>
                <did>Maximum likelihood approach.</did>
            </div>

            <div id="Disc-VS-Gen" class="step" data-rel-x="-500" data-rel-y="400" data-scale="0.5">
                <h1>Discriminative VS Generative</h1>
                <img src="images/discriminative_VS_generative.png" width="900"/>
                <h2>Partition VS fit<h2>
            </div>

            <!-- Embedding / manifold -->

            <div id="Manifold" class="step" data-rel-x="0" data-rel-y="600">
                <h1>Manifold hypothesis</h1>
                <img src="images/manifold.svg" width="900"/>
                <did>Samples lie on a lower dimensional manifold wrt the data space.</did>
            </div>

            <div id="Embedding" class="step" data-rel-x="1000" data-rel-y="0">
                <h1>Embedding space</h1>
                <img src="images/MNIST-tSNE.pbm" width="500"/>
                <did>
                    Samples can be mapped (from the manifold)<br/>
                    on a lower-dimensional (embedding) space<br/>
                    keeping (and disentangling) the latent characteristics.
                </did>
            </div>

            <!-- Approaches --> 

            <div id="Generative-approaches" class="step" data-rel-x="1000" data-rel-y="0">
                <h1>Generative approaches</h1>
                <img src="images/approaches.svg" width="900"/>
                <did>Complex distributions are mapped on simpler ones.</did>
            </div>

            <div id="VAE" class="step" data-rel-x="1500" data-rel-y="1500" data-rotate-z="45">
                <h1>Variational Auto-Encoders</h1>
                <img src="images/VAE.svg" width="800"/>
                <did>$$\log p(x) \ge \mathcal{L}(x) = \mathbb{E}_{q(x|z)}\log p(x|z) - KL(q(z|x)||p(z))$$</did>
            </div>

            <div id="NF" class="step" data-rel-x="0" data-rel-y="1500" data-rotate-z="135">
                <h1>Normalizing Flows</h1>
                <p>
                    Being $\{f_i\}$ diffeomorphisms:<tab/>
                    $p_{\mathcal{Z}_i}(z_i)=p_{\mathcal{Z}_{i+1}}(f_i(z_i))|\det Jf_i(z_i)|$
                </p>
                <a href="images/flow.gif" target="_blank">
                    <img src="images/nf_deform.png" width="350"/>
                </a>
                <p style="margin-top: 0;">
                    <img src="images/x.svg" width="100" style="display: inline-block; margin: 0;"/>
                    <span style="width: 70%; display: inline-block; margin: 0 10px;">
                        $$x = z_0 \rightarrow f_1(z_0) = z_1 \rightarrow \cdots \rightarrow f_n(z_{n-1}) = z_n$$
                        $$x = z_0 = f_1^{-1}(z_1) \leftarrow \cdots \leftarrow z_{n-1} = f_n^{-1}(z_n)$$
                    </span>
                    <img src="images/z.svg" width="100" style="display: inline-block; margin: 0;"/>
                </p>
            </div>

            <div id="DDPM" class="step" data-rel-x="-1500" data-rel-y="0" data-rotate-z="225">
                <h1>Denoising Diffusion Probabilistic Models</h1>
                <p>
                    <img src="images/x.svg" width="100" style="display: inline-block; margin: 0; vertical-align: middle;"/>
                    <img src="images/diffusion_model.png" width="666" style="display: inline-block; vertical-align: middle;"/>
                    <img src="images/z.svg" width="100" style="display: inline-block; margin: 0; vertical-align: middle;"/>
                </p>
                <did>Reaching the normal distribution via <a href="images/diffusion.gif" target="_blank">Brownian motion</a>.</did>
                <img src="images/DDPM.png" width="900"/>
            </div>

            <div id="GAN" class="step" data-rel-x="0" data-rel-y="-1500" data-rotate-z="315">
                <h1>Generative Adversarial Networks</h1>
                <p>
                    Train directly a generator network $G$...<br/>
                    <ptab/>...using a fancy loss function with a classifier $D$.
                </p>
                <p>
                    <img src="images/GAN.svg" width="400" style="display: inline-block; vertical-align: middle;"/>
                    <span style="display: inline-block;">
                    $$\small
                    \begin{eqnarray}
                        \mathcal{V}(G,D)&=&\min_G\max_D 
                        \mathbb{E}_x\left[\log D(x)\right] \\
                        &+& \mathbb[E]_z\left[\log(1-D(G(z)))\right]
                    \end{eqnarray}
                    $$
                    </span>
                </p>
            </div>

            <!-- Evaluation -->

            <div id="Classificaiton-performances" class="step" data-rel-x="3500" data-rel-y="-2000" data-rotate-z="360">
                <h1>Classification performances</h1>
                <p>
                    Samples complexity to reach the asymptotic error...<br/>
                    <ttab/>...in case of Vapnik-Chervonenkis dimension $n$:
                </p>
                <table style="width: 100%; margin-bottom: 30px;"><tr>
                    <td>Logistic regression: $O(n)$<td/>
                    <td>Naive Bayes: $O(\log n)$</td>
                </tr></table>
                <img src="images/class-perf.png" width="900"/>
                <center>BUT</center>
                $$\epsilon(h_{Dis,\infty}) \lt \epsilon(h_{Gen,\infty})$$
                <a href="https://ai.stanford.edu/~ang/papers/nips01-discriminativegenerative.pdf">
                    <cit>"On Discriminative vs. Generative Classifiers: A comparison of logistic regression and naive Bayes", Andrew Y. Ng, Michael I. Jordan</cit>
                </a>
            </div>

            <div id="Generation-quality" class="step" data-rel-x="1000" data-rel-y="-1000" data-rotate-z="270">
                <h1>Generation quality</h1>
                Hard task, currently a research topic.
                Some common metric issues:
                <dl>
                    <dt>Slow</dt>
                    <dd>Biased, comparing distributions requires many samples (~50k).</dd>
                    <dt>Perceptual quality</dt>
                    <dd>Difficulty assessing blurriness, noise, artefacts, ...</dd>
                    <dt>Different media</dt>
                    <dd>Do not work only with images: consider videos, text, audio, ...</dd>
                </dl>
                <img src="images/PPL.png" width="700"/>
                <a href="https://arxiv.org/pdf/2103.09396.pdf">
                    <cit>"Pros and Cons of GAN Evaluation Measures: New Developments", Ali Borji</cit>
                </a>
            </div>

            <div id="Distribution-adherence" class="step" data-rel-x="-1000" data-rel-y="-1000" data-rotate-z="180">
                <h1>Distribution adherence</h1>
                Some common generator issues:
                <dl>
                    <dt>Memorization</dt>
                    <dd>The model returns samples too similar to the training set.</dd>
                    <dt>Mode collapse</dt>
                    <dd>All generated samples are related to a restricted set of modes.</dd>
                    <dt>Off manifold</dt>
                    <dd>Generated samples lie outside the data manifold (eg. interpolation).</dd>
                </dl>
                <img src="images/prerec.png" width="900"/>
                <a href="https://arxiv.org/pdf/2103.09396.pdf">
                    <cit>"Pros and Cons of GAN Evaluation Measures: New Developments", Ali Borji</cit>
                </a>
            </div>

            <div id="Embedding-quality" class="step" data-rel-x="-1000" data-rel-y="1000" data-rotate-z="90">
                <h1>Embedding quality</h1>
                Some desirable aspects of the empedding space:
                <dl>
                    <dt>Clustering</dt>
                    <dd>The embedding clusters samples with similar characteristics.</dd>
                    <dt>Compression</dt>
                    <dd>Data compressed without significant information loss.</dd>
                    <dt>Disentanglement</dt>
                    <dd>Latent variables change different characteristics of data.</dd>
                </dl>
                <img src="images/emotions.png" width="800"/>
                <a href="https://deepgenerativemodels.github.io/assets/slides/cs236_lecture15.pdf">
                    <cit>"Deep generative models", Standford, 2021, CS236 - Lecture 15, Stefano Ermon, Yang Song</cit>
                </a>
                <a href="https://arxiv.org/pdf/2205.06102v1.pdf">
                    <cit>"Tensor-based Emotion Editing in the StyleGAN Latent Space", Rene Haas, Stella Graßhof, and Sami S. Brandt</cit>
                </a>
            </div>

            <div id="Applications01" class="step" data-rel-x="500" data-rel-y="2500" data-rotate-z="45">
                <h1>A new world of applications</h1>
                <dl>
                    <dt>Capturing the distribution of data:</dt>
                    <dd>
                        sample
                        <span style="display: inline-block; vertical-align: middle;">
                            <img src="images/manga.png" width="200"/>
                        </span>
                        <tab/>
                        project
                        <span style="display: inline-block; vertical-align: middle;">
                            <img src="images/gab.png" width="200"/>
                        </span>
                        <span style="display: inline-block; vertical-align: middle;">
                            <img src="images/gab_proj.png" width="200"/>
                        </span>
                    </dd>
                    
                    <dt>Detecting outliers/anomalies:</dt>
                    <dd>
                        <img src="images/AnoVAE.png" width="900"/>
                        <cit>"Autoencoders for Unsupervised Anomaly Segmentation in Brain MR Images: A Comparative Study",
                             Christoph Baur, Stefan Denner, Benedikt Wiestler, Shadi Albarqouni and Nassir Navab</cit>
                    </dd>
                </dl>
            </div>

            <div id="Applications02" class="step" data-rel-x="1500" data-rel-y="0" data-rotate-z="45">
                <h1>A new world of applications</h1>
                <dl>
                    <dt>Latent-space feature editing:</dt>
                    <dd>
                        <img src="images/InterFaceGAN.png" width="900"/>
                        <cit>"Interpreting the Latent Space of GANs for Semantic Face Editing",
                             Yujun Shen, Jinjin Gu, Xiaoou Tang, Bolei Zhou</cit>
                    </dd>
                </dl>
            </div>

            <div id="Applications03" class="step" data-rel-x="1500" data-rel-y="0" data-rotate-z="45">
                <h1>A new world of applications</h1>
                <dl>
                    <dt>Image transformation via conditional generation:</dt>
                    <dd>
                        <img src="images/pix2pix.jpeg" width="900"/>
                        <cit>"Image-to-Image Translation with Conditional Adversarial Nets",
                             Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei A. Efros</cit>
                    </dd>
                </dl>
            </div>

            <div id="Applications04" class="step" data-rel-x="1500" data-rel-y="0" data-rotate-z="45">
                <h1>A new world of applications</h1>
                <dl>
                    <dt>Aerial images semantic segmentation:</dt>
                    <dd>
                        <img src="images/pix2pix_semseg_aerial.png" height="200"/>
                        <a href="https://github.com/A2Amir/Pix2Pix-for-Semantic-Segmentation-of-Satellite-Images">
                            <cit>"What Is Pix2Pix and How To Use It for Semantic Segmentation of Satellite Images?"</cit>
                        </a>
                    </dd>

                    <dt>Cell membrane and nucleus semantic segmentation:</dt>
                    <dd>
                        <img src="images/pix2pix_semseg_cell.png" width="900"/>
                        <cit>"Cell Image Segmentation by Integrating Pix2pixs for Each Class",
                             Hiroki Tsuda and Kazuhiro Hotta</cit>
                    </dd>
                </dl>
            </div>

            <div id="Applications05" class="step" data-rel-x="-1500" data-rel-y="1500" data-rotate-z="45">
                <h1>A new world of applications</h1>
                <dl>
                    <dt>Domain adaptation</dt>
                    <dd>
                        <img src="images/AttentionGAN.png" width="800"/>
                        <a href="https://arxiv.org/pdf/1911.11897.pdf">
                            <cit>"AttentionGAN: Unpaired Image-to-Image Translation using Attention-Guided Generative Adversarial Networks", Hao Tang, Hong Liu, Dan Xu, Philip H.S. Torr, and Nicu Sebe</cit>
                        </a>
                    </dd>
                </dl>
            </div>

            <div id="Applications06" class="step" data-rel-x="-1500" data-rel-y="1500" data-rotate-z="45">
                <h2 style="margin: 0 0;">Text-to-images short story</h2>
                <div id="LastSupper" style="width: 70%; margin: 0 auto; overflow-x: scroll;">
                    <a href="images/LastSupper.jpeg" target="_blank">
                        <img src="images/LastSupper.jpeg" height="320"/>
                    </a>
                </div>
                <script>
                    function adjustLastSupper() { 
                        var elem = document.getElementById("LastSupper");
                        var elemWidth = elem.scrollWidth;
                        var elemVisibleWidth = elem.offsetWidth;
                        elem.scrollLeft = (elemWidth - elemVisibleWidth) * 28 / 50;
                    }
                </script>
                <a href="https://mobile.twitter.com/gabe_ragland/status/1539005324983578624/photo/1">
                    <did>@Dalle2 Pics, Twitter</did>
                </a>
                <dl>
                    <dt>DALL-E (Autoregressive Model)</dt>
                    <dd>
                        <a href="https://arxiv.org/pdf/2102.12092.pdf">
                            <cit>"Zero-Shot Text-to-Image Generation"</cit>
                        </a>
                    </dd>

                    <dt>GLIDE (Diffusion Model)</dt>
                    <dd>
                        <a href="https://arxiv.org/pdf/2112.10741.pdf">
                            <cit>"GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models"</cit>
                        </a>
                    </dd>

                    <dt>DALL-E 2 (Diffusion Model)</dt>
                    <dd>
                        <a href="https://cdn.openai.com/papers/dall-e-2.pdf">
                            <cit>"Hierarchical Text-Conditional Image Generation with CLIP Latents"</cit>
                        </a>
                    </dd>
                    
                    <dt>Imagen (Diffusion Model)</dt>
                    <dd>
                        <a href="https://imagen.research.google/paper.pdf">
                            <cit>"Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding"</cit>
                        </a>
                    </dd>
                </dl>
            </div>

        </div>

        <div id="impress-toolbar"></div>
        <div class="impress-progressbar"><div></div></div>
        <div class="impress-progress"></div>

        <script type="text/x-mathjax-config">
          MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['$','$'], ['\\(','\\)'] ]
          },
          TeX: {
            Macros: {
              energy: "e",
              eqby: ["\\stackrel{#1}{=}",1],
            }
          }
          });
        </script>
        <script type="text/javascript" src="js/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/javascript" src="js/impress.js"></script>

        <script>
            impress().init();
            adjustLastSupper();
        </script>
    </body>
</html>
